{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "penguins = pd.read_csv(\"../datasets/penguins.csv\")\n",
    "\n",
    "columns = [\"Body Mass (g)\", \"Flipper Length (mm)\", \"Culmen Length (mm)\"]\n",
    "target_name = \"Species\"\n",
    "\n",
    "# Remove lines with missing values for the columns of interest\n",
    "penguins_non_missing = penguins[columns + [target_name]].dropna()\n",
    "\n",
    "data = penguins_non_missing[columns]\n",
    "target = penguins_non_missing[target_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adelie Penguin (Pygoscelis adeliae)          151\n",
       "Gentoo penguin (Pygoscelis papua)            123\n",
       "Chinstrap penguin (Pygoscelis antarctica)     68\n",
       "Name: Species, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "model = Pipeline(steps=[\n",
    "    (\"preprocessor\", StandardScaler()),\n",
    "    (\"classifier\", KNeighborsClassifier(n_neighbors=5)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the pipeline using stratified 10-fold cross-validation with the balanced-accuracy scoring metric to choose the correct statement in the list below.\n",
    "\n",
    "You can use:\n",
    "\n",
    "sklearn.model_selection.cross_validate to perform the cross-validation routine;\n",
    "provide an integer 10 to the parameter cv of cross_validate to use the cross-validation with 10 folds;\n",
    "provide the string \"balanced_accuracy\" to the parameter scoring of cross_validate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) The average cross-validated test balanced accuracy of the above pipeline is between 0.9 and 1.0\n",
    "\n",
    "b) The average cross-validated test balanced accuracy of the above pipeline is between 0.8 and 0.9\n",
    "\n",
    "c) The average cross-validated test balanced accuracy of the above pipeline is between 0.5 and 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00688362, 0.00686026, 0.0050416 , 0.00816345, 0.00452375,\n",
       "        0.00464201, 0.00452185, 0.00470209, 0.00454974, 0.00466847]),\n",
       " 'score_time': array([0.00474024, 0.00475216, 0.00435305, 0.00440693, 0.00406003,\n",
       "        0.00427771, 0.00416422, 0.00430012, 0.00401139, 0.00418925]),\n",
       " 'test_score': array([1.        , 1.        , 1.        , 0.91880342, 0.88253968,\n",
       "        0.95238095, 0.97777778, 0.93015873, 0.90793651, 0.95238095])}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "cv_results = cross_validate(model, data, target, cv=10, n_jobs=2, scoring=\"balanced_accuracy\")\n",
    "\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the evaluation by setting the parameters in order to select the correct statements in the list below. We recall that you can use model.get_params() to list the parameters of the pipeline and use model.set_params(param_name=param_value) to update them. Remember that one way to compare two models is comparing the cross-validation test scores of both models fold-to-fold, i.e. counting the number of folds where one model has a better test score than the other.\n",
    "\n",
    " a) Looking at the individual cross-validation scores, using a model with n_neighbors=5 is substantially better (at least 7 of the cross-validations scores are better) than a model with n_neighbors=51\n",
    " \n",
    " b) Looking at the individual cross-validation scores, using a model with n_neighbors=5 is substantially better (at least 7 of the cross-validations scores are better) than a model with n_neighbors=101\n",
    " \n",
    " c) Looking at the individual cross-validation scores, a 5 nearest neighbors using a StandardScaler is substantially better (at least 7 of the cross-validations scores are better) than a 5 nearest neighbors using the raw features (without scaling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 59.7 ms, sys: 7.66 ms, total: 67.4 ms\n",
      "Wall time: 178 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__n_neighbors</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005189</td>\n",
       "      <td>0.000875</td>\n",
       "      <td>0.003881</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classifier__n_neighbors': 5}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.961765</td>\n",
       "      <td>0.032353</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004760</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.004513</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>51</td>\n",
       "      <td>{'classifier__n_neighbors': 51}</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.956050</td>\n",
       "      <td>0.027209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004541</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.004381</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>101</td>\n",
       "      <td>{'classifier__n_neighbors': 101}</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.917983</td>\n",
       "      <td>0.031780</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.005189      0.000875         0.003881        0.000287   \n",
       "1       0.004760      0.000493         0.004513        0.000607   \n",
       "2       0.004541      0.000156         0.004381        0.000150   \n",
       "\n",
       "  param_classifier__n_neighbors                            params  \\\n",
       "0                             5    {'classifier__n_neighbors': 5}   \n",
       "1                            51   {'classifier__n_neighbors': 51}   \n",
       "2                           101  {'classifier__n_neighbors': 101}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           1.000000           1.000000           1.000000           0.941176   \n",
       "1           0.971429           0.971429           1.000000           0.911765   \n",
       "2           0.914286           0.971429           0.970588           0.911765   \n",
       "\n",
       "   split4_test_score  split5_test_score  split6_test_score  split7_test_score  \\\n",
       "0           0.911765           0.970588           0.970588           0.941176   \n",
       "1           0.911765           0.970588           0.941176           0.970588   \n",
       "2           0.882353           0.911765           0.882353           0.911765   \n",
       "\n",
       "   split8_test_score  split9_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.911765           0.970588         0.961765        0.032353   \n",
       "1           0.941176           0.970588         0.956050        0.027209   \n",
       "2           0.882353           0.941176         0.917983        0.031780   \n",
       "\n",
       "   rank_test_score  \n",
       "0                1  \n",
       "1                2  \n",
       "2                3  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__n_neighbors': (5, 51, 101)\n",
    "}\n",
    "model_grid_search = GridSearchCV(model, param_grid=param_grid,\n",
    "                                 n_jobs=2, cv=10)\n",
    "model_grid_search.fit(data, target)\n",
    "\n",
    "cv_results = pd.DataFrame(model_grid_search.cv_results_).sort_values(\n",
    "    \"mean_test_score\", ascending=False)\n",
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que 5 y 51 funcionan parecido pero siempre mejor que sin escalar. Tiene sentido, al ser un modelo basado en distancias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005153</td>\n",
       "      <td>0.005711</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002942</td>\n",
       "      <td>0.004028</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002485</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.794118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004050</td>\n",
       "      <td>0.003533</td>\n",
       "      <td>0.794118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002531</td>\n",
       "      <td>0.003486</td>\n",
       "      <td>0.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.002597</td>\n",
       "      <td>0.003470</td>\n",
       "      <td>0.764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.002942</td>\n",
       "      <td>0.003556</td>\n",
       "      <td>0.882353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.002493</td>\n",
       "      <td>0.003502</td>\n",
       "      <td>0.794118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.002493</td>\n",
       "      <td>0.003471</td>\n",
       "      <td>0.911765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.002861</td>\n",
       "      <td>0.003479</td>\n",
       "      <td>0.852941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score\n",
       "0  0.005153    0.005711    0.742857\n",
       "1  0.002942    0.004028    0.800000\n",
       "2  0.002485    0.003500    0.794118\n",
       "3  0.004050    0.003533    0.794118\n",
       "4  0.002531    0.003486    0.647059\n",
       "5  0.002597    0.003470    0.764706\n",
       "6  0.002942    0.003556    0.882353\n",
       "7  0.002493    0.003502    0.794118\n",
       "8  0.002493    0.003471    0.911765\n",
       "9  0.002861    0.003479    0.852941"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unscaled_model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "\n",
    "cv_results = cross_validate(unscaled_model, data, target, cv=10, n_jobs=2)\n",
    "cv_results = pd.DataFrame(cv_results)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Box-Cox method is common preprocessing strategy for positive values. The other preprocessors work both for any kind of numerical features. If you are curious to read the details about those method, please feel free to read them up in the preprocessing chapter of the scikit-learn user guide but this is not required to answer the quiz questions.\n",
    "\n",
    "Use sklearn.model_selection.GridSearchCV to study the impact of the choice of the preprocessor and the number of neighbors on the stratified 10-fold cross-validated balanced_accuracy metric. We want to study the n_neighbors in the range [5, 51, 101] and preprocessor in the range all_preprocessors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLARO, YO PUEDO HACER VARIOS PIPELINES, UNO CON CADA PROCESOR, O SIN PROCESOR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does this makes sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0. ],\n",
       "        [0.1],\n",
       "        [0.2],\n",
       "        [0.3],\n",
       "        [0.4],\n",
       "        [0.5],\n",
       "        [0.6],\n",
       "        [0.7],\n",
       "        [0.8],\n",
       "        [0.9],\n",
       "        [1. ]]),\n",
       " array([[0. ],\n",
       "        [0.1],\n",
       "        [0.2],\n",
       "        [0.3],\n",
       "        [0.4],\n",
       "        [0.5],\n",
       "        [0.6],\n",
       "        [0.7],\n",
       "        [0.8],\n",
       "        [0.9],\n",
       "        [1. ]]))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "rng = np.random.RandomState(0)\n",
    "X = np.array(range(0, 11)).reshape(-1, 1)\n",
    "qt1, qt2 = QuantileTransformer(n_quantiles=10, random_state=0), QuantileTransformer(n_quantiles=3, random_state=42)\n",
    "qt.fit_transform(X), qt2.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Transform features using quantiles information.\n",
    "\n",
    "This method transforms the features to follow a uniform or a normal distribution. Therefore, for a given feature, this transformation tends to spread out the most frequent values. It also reduces the impact of (marginal) outliers: this is therefore a robust preprocessing scheme.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.13824745],\n",
       "        [ 0.25568053],\n",
       "        [ 0.28647607],\n",
       "        [ 0.31445874],\n",
       "        [ 0.44871043],\n",
       "        [ 0.4621607 ],\n",
       "        [ 0.47419529],\n",
       "        [ 0.53041875],\n",
       "        [ 0.53601089],\n",
       "        [ 0.57826693],\n",
       "        [ 0.58341858],\n",
       "        [ 0.6000393 ],\n",
       "        [ 0.60264963],\n",
       "        [ 0.61096581],\n",
       "        [ 0.66340465],\n",
       "        [ 0.69025943],\n",
       "        [ 0.71610905],\n",
       "        [ 0.7375221 ],\n",
       "        [ 0.7446845 ],\n",
       "        [ 0.86356838],\n",
       "        [ 0.87351977],\n",
       "        [ 0.94101309],\n",
       "        [ 0.9668895 ],\n",
       "        [ 1.0602233 ],\n",
       "        [ 1.06743866]]),\n",
       " array([[0.        ],\n",
       "        [0.09871873],\n",
       "        [0.10643612],\n",
       "        [0.11754671],\n",
       "        [0.21017437],\n",
       "        [0.21945445],\n",
       "        [0.23498666],\n",
       "        [0.32443642],\n",
       "        [0.33333333],\n",
       "        [0.41360794],\n",
       "        [0.42339464],\n",
       "        [0.46257841],\n",
       "        [0.47112236],\n",
       "        [0.49834237],\n",
       "        [0.59986536],\n",
       "        [0.63390302],\n",
       "        [0.66666667],\n",
       "        [0.68873101],\n",
       "        [0.69611125],\n",
       "        [0.81280699],\n",
       "        [0.82160354],\n",
       "        [0.88126439],\n",
       "        [0.90516028],\n",
       "        [0.99319435],\n",
       "        [1.        ]]))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "rng = np.random.RandomState(0)\n",
    "X = np.sort(rng.normal(loc=0.5, scale=0.25, size=(25, 1)), axis=0)\n",
    "qt = QuantileTransformer(n_quantiles=10, random_state=0)\n",
    "\n",
    "X, qt.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Box-Cox\n",
    "\n",
    "Apply a power transform featurewise to make data more Gaussian-like.\n",
    "\n",
    "Power transforms are a family of parametric, monotonic transformations that are applied to make data more Gaussian-like. This is useful for modeling issues related to heteroscedasticity (non-constant variance), or other situations where normality is desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.31616039 -0.70710678]\n",
      " [ 0.20998268 -0.70710678]\n",
      " [ 1.1061777   1.41421356]] [[-1.33269291 -0.70710678]\n",
      " [ 0.25653283 -0.70710678]\n",
      " [ 1.07616008  1.41421356]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "pt, pt2 = PowerTransformer(), PowerTransformer(\"box-cox\")\n",
    "data1 = [[1, 2], [3, 2], [4, 5]]\n",
    "pt.fit(data1)\n",
    "pt2.fit(data1)\n",
    "\n",
    "print(pt.transform(data1), pt2.transform(data1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Using preprocessor: None\n",
      "                             params  mean_test_score  split0_test_score  \\\n",
      "0    {'classifier__n_neighbors': 5}         0.798403           0.742857   \n",
      "1   {'classifier__n_neighbors': 51}         0.728151           0.742857   \n",
      "2  {'classifier__n_neighbors': 101}         0.736891           0.742857   \n",
      "\n",
      "   split1_test_score  split2_test_score  split3_test_score  \n",
      "0           0.800000           0.794118           0.794118  \n",
      "1           0.685714           0.735294           0.705882  \n",
      "2           0.714286           0.705882           0.705882  \n",
      " \n",
      " Using preprocessor: StandardScaler()\n",
      "                             params  mean_test_score  split0_test_score  \\\n",
      "0    {'classifier__n_neighbors': 5}         0.961765           1.000000   \n",
      "1   {'classifier__n_neighbors': 51}         0.956050           0.971429   \n",
      "2  {'classifier__n_neighbors': 101}         0.917983           0.914286   \n",
      "\n",
      "   split1_test_score  split2_test_score  split3_test_score  \n",
      "0           1.000000           1.000000           0.941176  \n",
      "1           0.971429           1.000000           0.911765  \n",
      "2           0.971429           0.970588           0.911765  \n",
      " \n",
      " Using preprocessor: MinMaxScaler()\n",
      "                             params  mean_test_score  split0_test_score  \\\n",
      "0    {'classifier__n_neighbors': 5}         0.958908           1.000000   \n",
      "1   {'classifier__n_neighbors': 51}         0.944370           0.942857   \n",
      "2  {'classifier__n_neighbors': 101}         0.909328           0.914286   \n",
      "\n",
      "   split1_test_score  split2_test_score  split3_test_score  \n",
      "0           0.971429           1.000000           0.970588  \n",
      "1           0.971429           1.000000           0.911765  \n",
      "2           0.914286           0.970588           0.911765  \n",
      " \n",
      " Using preprocessor: QuantileTransformer(n_quantiles=100)\n",
      "                             params  mean_test_score  split0_test_score  \\\n",
      "0    {'classifier__n_neighbors': 5}         0.959076           0.971429   \n",
      "1   {'classifier__n_neighbors': 51}         0.950336           0.914286   \n",
      "2  {'classifier__n_neighbors': 101}         0.874034           0.914286   \n",
      "\n",
      "   split1_test_score  split2_test_score  split3_test_score  \n",
      "0           0.942857           1.000000           0.941176  \n",
      "1           0.971429           1.000000           0.911765  \n",
      "2           0.914286           0.882353           0.911765  \n",
      " \n",
      " Using preprocessor: PowerTransformer(method='box-cox')\n",
      "                             params  mean_test_score  split0_test_score  \\\n",
      "0    {'classifier__n_neighbors': 5}         0.955966           1.000000   \n",
      "1   {'classifier__n_neighbors': 51}         0.944370           0.942857   \n",
      "2  {'classifier__n_neighbors': 101}         0.906218           0.942857   \n",
      "\n",
      "   split1_test_score  split2_test_score  split3_test_score  \n",
      "0           0.971429           1.000000           0.911765  \n",
      "1           0.971429           1.000000           0.911765  \n",
      "2           0.942857           0.941176           0.941176  \n",
      " \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "all_preprocessors = [\n",
    "    None,\n",
    "    StandardScaler(),\n",
    "    MinMaxScaler(),\n",
    "    QuantileTransformer(n_quantiles=100),\n",
    "    PowerTransformer(method=\"box-cox\"),\n",
    "]\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__n_neighbors': (5, 51, 101)\n",
    "}\n",
    "\n",
    "for prep in all_preprocessors:\n",
    "    print(f\" Using preprocessor: {prep}\")\n",
    "    model = Pipeline(steps=[\n",
    "    (\"preprocessor\", prep),\n",
    "    (\"classifier\", KNeighborsClassifier(n_neighbors=5)),])\n",
    "    model_grid_search = GridSearchCV(model, param_grid=param_grid,\n",
    "                                 n_jobs=2, cv=10)\n",
    "    model_grid_search.fit(data, target)\n",
    "    cv_results = pd.DataFrame(model_grid_search.cv_results_).sort_values(\n",
    "    \"mean_test_score\", ascending=False)\n",
    "    print(cv_results.sort_values(\"param_classifier__n_neighbors\").head()[[\"params\", \"mean_test_score\", \"split0_test_score\", \"split1_test_score\", \"split2_test_score\", \"split3_test_score\"]])\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Which of the following statements hold:\n",
    "\n",
    " a) Looking at the individual cross-validation scores, the best ranked model using a StandardScaler is substantially better (at least 7 of the cross-validations scores are better) than using any other processor \n",
    " \n",
    " b) Using any of the preprocessors has always a better ranking than using no processor, irrespective of the value of n_neighbors \n",
    " \n",
    " c) Looking at the individual cross-validation scores, the model with n_neighbors=5 and StandardScaler is substantially better (at least 7 of the cross-validations scores are better) than the model with n_neighbors=51 and StandardScaler \n",
    " \n",
    " d) Looking at the individual cross-validation scores, the model with n_neighbors=51 and StandardScaler is substantially better (at least 7 of the cross-validations scores are better) than the model with n_neighbors=101 and StandardScaler\n",
    "\n",
    "- unanswered\n",
    "Select all answers that apply\n",
    "Hint: pass {\"preprocessor\": all_preprocessors, \"classifier__n_neighbors\": [5, 51, 101]} for the param_grid argument to the GridSearchCV class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__n_neighbors</th>\n",
       "      <th>param_preprocessor</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004404</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.004077</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>5</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>{'classifier__n_neighbors': 5, 'preprocessor': StandardScaler()}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.918803</td>\n",
       "      <td>0.882540</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.930159</td>\n",
       "      <td>0.907937</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952198</td>\n",
       "      <td>0.039902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004170</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.004032</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>5</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>{'classifier__n_neighbors': 5, 'preprocessor': MinMaxScaler()}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.882540</td>\n",
       "      <td>0.930159</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.907937</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.947778</td>\n",
       "      <td>0.034268</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007212</td>\n",
       "      <td>0.001843</td>\n",
       "      <td>0.006711</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>5</td>\n",
       "      <td>QuantileTransformer</td>\n",
       "      <td>{'classifier__n_neighbors': 5, 'preprocessor': QuantileTransformer(n_quantiles=100)}</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.926740</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.918803</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.930159</td>\n",
       "      <td>0.907937</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.947094</td>\n",
       "      <td>0.033797</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.009083</td>\n",
       "      <td>0.002241</td>\n",
       "      <td>0.004620</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>5</td>\n",
       "      <td>PowerTransformer</td>\n",
       "      <td>{'classifier__n_neighbors': 5, 'preprocessor': PowerTransformer(method='box-cox')}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.863248</td>\n",
       "      <td>0.882540</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.930159</td>\n",
       "      <td>0.907937</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.946960</td>\n",
       "      <td>0.047387</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.004891</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0.004522</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>51</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>{'classifier__n_neighbors': 51, 'preprocessor': StandardScaler()}</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.863248</td>\n",
       "      <td>0.882540</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.930159</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.941880</td>\n",
       "      <td>0.038905</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.005252</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.004747</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>51</td>\n",
       "      <td>QuantileTransformer</td>\n",
       "      <td>{'classifier__n_neighbors': 51, 'preprocessor': QuantileTransformer(n_quantiles=100)}</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.863248</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.930159</td>\n",
       "      <td>0.930159</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.927277</td>\n",
       "      <td>0.043759</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.008145</td>\n",
       "      <td>0.000682</td>\n",
       "      <td>0.004722</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>51</td>\n",
       "      <td>PowerTransformer</td>\n",
       "      <td>{'classifier__n_neighbors': 51, 'preprocessor': PowerTransformer(method='box-cox')}</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.863248</td>\n",
       "      <td>0.834921</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.907937</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.930159</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.922833</td>\n",
       "      <td>0.047883</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.004225</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.004331</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>51</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>{'classifier__n_neighbors': 51, 'preprocessor': MinMaxScaler()}</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.863248</td>\n",
       "      <td>0.834921</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.907937</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.930159</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.920293</td>\n",
       "      <td>0.045516</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.004206</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.004750</td>\n",
       "      <td>0.000668</td>\n",
       "      <td>101</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>{'classifier__n_neighbors': 101, 'preprocessor': StandardScaler()}</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.863248</td>\n",
       "      <td>0.834921</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.834921</td>\n",
       "      <td>0.882540</td>\n",
       "      <td>0.834921</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.876642</td>\n",
       "      <td>0.041618</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.004105</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.004586</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>101</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>{'classifier__n_neighbors': 101, 'preprocessor': MinMaxScaler()}</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.863248</td>\n",
       "      <td>0.834921</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.765079</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.834921</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.862357</td>\n",
       "      <td>0.046244</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.008537</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.005423</td>\n",
       "      <td>0.001417</td>\n",
       "      <td>101</td>\n",
       "      <td>PowerTransformer</td>\n",
       "      <td>{'classifier__n_neighbors': 101, 'preprocessor': PowerTransformer(method='box-cox')}</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.787302</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.812698</td>\n",
       "      <td>0.882540</td>\n",
       "      <td>0.834921</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.041000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.005394</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.004820</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>101</td>\n",
       "      <td>QuantileTransformer</td>\n",
       "      <td>{'classifier__n_neighbors': 101, 'preprocessor': QuantileTransformer(n_quantiles=100)}</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.863248</td>\n",
       "      <td>0.765079</td>\n",
       "      <td>0.812698</td>\n",
       "      <td>0.765079</td>\n",
       "      <td>0.834921</td>\n",
       "      <td>0.739683</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.812991</td>\n",
       "      <td>0.044788</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002766</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.004291</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>{'classifier__n_neighbors': 5, 'preprocessor': None}</td>\n",
       "      <td>0.664683</td>\n",
       "      <td>0.736020</td>\n",
       "      <td>0.741026</td>\n",
       "      <td>0.704274</td>\n",
       "      <td>0.584127</td>\n",
       "      <td>0.669841</td>\n",
       "      <td>0.834921</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.882540</td>\n",
       "      <td>0.838095</td>\n",
       "      <td>0.739838</td>\n",
       "      <td>0.086685</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>101</td>\n",
       "      <td>None</td>\n",
       "      <td>{'classifier__n_neighbors': 101, 'preprocessor': None}</td>\n",
       "      <td>0.618056</td>\n",
       "      <td>0.593162</td>\n",
       "      <td>0.574359</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.588889</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.613857</td>\n",
       "      <td>0.031472</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.002693</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.004202</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>51</td>\n",
       "      <td>None</td>\n",
       "      <td>{'classifier__n_neighbors': 51, 'preprocessor': None}</td>\n",
       "      <td>0.618056</td>\n",
       "      <td>0.567521</td>\n",
       "      <td>0.596581</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.605182</td>\n",
       "      <td>0.036480</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "1        0.004404      0.000249         0.004077        0.000084   \n",
       "2        0.004170      0.000137         0.004032        0.000068   \n",
       "3        0.007212      0.001843         0.006711        0.002439   \n",
       "4        0.009083      0.002241         0.004620        0.000834   \n",
       "6        0.004891      0.001747         0.004522        0.000343   \n",
       "8        0.005252      0.000111         0.004747        0.000605   \n",
       "9        0.008145      0.000682         0.004722        0.000665   \n",
       "7        0.004225      0.000346         0.004331        0.000140   \n",
       "11       0.004206      0.000059         0.004750        0.000668   \n",
       "12       0.004105      0.000219         0.004586        0.000210   \n",
       "14       0.008537      0.000703         0.005423        0.001417   \n",
       "13       0.005394      0.000170         0.004820        0.000276   \n",
       "0        0.002766      0.000189         0.004291        0.000467   \n",
       "10       0.002607      0.000113         0.004500        0.000519   \n",
       "5        0.002693      0.000050         0.004202        0.000075   \n",
       "\n",
       "   param_classifier__n_neighbors   param_preprocessor  \\\n",
       "1                              5       StandardScaler   \n",
       "2                              5         MinMaxScaler   \n",
       "3                              5  QuantileTransformer   \n",
       "4                              5     PowerTransformer   \n",
       "6                             51       StandardScaler   \n",
       "8                             51  QuantileTransformer   \n",
       "9                             51     PowerTransformer   \n",
       "7                             51         MinMaxScaler   \n",
       "11                           101       StandardScaler   \n",
       "12                           101         MinMaxScaler   \n",
       "14                           101     PowerTransformer   \n",
       "13                           101  QuantileTransformer   \n",
       "0                              5                 None   \n",
       "10                           101                 None   \n",
       "5                             51                 None   \n",
       "\n",
       "                                                                                    params  \\\n",
       "1                         {'classifier__n_neighbors': 5, 'preprocessor': StandardScaler()}   \n",
       "2                           {'classifier__n_neighbors': 5, 'preprocessor': MinMaxScaler()}   \n",
       "3     {'classifier__n_neighbors': 5, 'preprocessor': QuantileTransformer(n_quantiles=100)}   \n",
       "4       {'classifier__n_neighbors': 5, 'preprocessor': PowerTransformer(method='box-cox')}   \n",
       "6                        {'classifier__n_neighbors': 51, 'preprocessor': StandardScaler()}   \n",
       "8    {'classifier__n_neighbors': 51, 'preprocessor': QuantileTransformer(n_quantiles=100)}   \n",
       "9      {'classifier__n_neighbors': 51, 'preprocessor': PowerTransformer(method='box-cox')}   \n",
       "7                          {'classifier__n_neighbors': 51, 'preprocessor': MinMaxScaler()}   \n",
       "11                      {'classifier__n_neighbors': 101, 'preprocessor': StandardScaler()}   \n",
       "12                        {'classifier__n_neighbors': 101, 'preprocessor': MinMaxScaler()}   \n",
       "14    {'classifier__n_neighbors': 101, 'preprocessor': PowerTransformer(method='box-cox')}   \n",
       "13  {'classifier__n_neighbors': 101, 'preprocessor': QuantileTransformer(n_quantiles=100)}   \n",
       "0                                     {'classifier__n_neighbors': 5, 'preprocessor': None}   \n",
       "10                                  {'classifier__n_neighbors': 101, 'preprocessor': None}   \n",
       "5                                    {'classifier__n_neighbors': 51, 'preprocessor': None}   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "1            1.000000           1.000000           1.000000   \n",
       "2            1.000000           0.952381           1.000000   \n",
       "3            0.952381           0.926740           1.000000   \n",
       "4            1.000000           0.977778           1.000000   \n",
       "6            0.952381           0.977778           1.000000   \n",
       "8            0.857143           0.952381           1.000000   \n",
       "9            0.904762           0.977778           1.000000   \n",
       "7            0.904762           0.952381           1.000000   \n",
       "11           0.857143           0.952381           0.944444   \n",
       "12           0.857143           0.857143           0.944444   \n",
       "14           0.904762           0.904762           0.888889   \n",
       "13           0.857143           0.857143           0.777778   \n",
       "0            0.664683           0.736020           0.741026   \n",
       "10           0.618056           0.593162           0.574359   \n",
       "5            0.618056           0.567521           0.596581   \n",
       "\n",
       "    split3_test_score  split4_test_score  split5_test_score  \\\n",
       "1            0.918803           0.882540           0.952381   \n",
       "2            0.944444           0.882540           0.930159   \n",
       "3            0.918803           0.904762           1.000000   \n",
       "4            0.863248           0.882540           0.952381   \n",
       "6            0.863248           0.882540           0.952381   \n",
       "8            0.863248           0.904762           0.904762   \n",
       "9            0.863248           0.834921           0.952381   \n",
       "7            0.863248           0.834921           0.952381   \n",
       "11           0.863248           0.834921           0.857143   \n",
       "12           0.863248           0.834921           0.857143   \n",
       "14           0.888889           0.787302           0.809524   \n",
       "13           0.863248           0.765079           0.812698   \n",
       "0            0.704274           0.584127           0.669841   \n",
       "10           0.564103           0.588889           0.644444   \n",
       "5            0.564103           0.533333           0.644444   \n",
       "\n",
       "    split6_test_score  split7_test_score  split8_test_score  \\\n",
       "1            0.977778           0.930159           0.907937   \n",
       "2            0.955556           0.952381           0.907937   \n",
       "3            0.977778           0.930159           0.907937   \n",
       "4            0.955556           0.930159           0.907937   \n",
       "6            0.955556           0.952381           0.930159   \n",
       "8            0.977778           0.930159           0.930159   \n",
       "9            0.907937           0.952381           0.930159   \n",
       "7            0.907937           0.952381           0.930159   \n",
       "11           0.834921           0.882540           0.834921   \n",
       "12           0.765079           0.904762           0.834921   \n",
       "14           0.812698           0.882540           0.834921   \n",
       "13           0.765079           0.834921           0.739683   \n",
       "0            0.834921           0.742857           0.882540   \n",
       "10           0.622222           0.622222           0.644444   \n",
       "5            0.622222           0.622222           0.644444   \n",
       "\n",
       "    split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "1            0.952381         0.952198        0.039902                1  \n",
       "2            0.952381         0.947778        0.034268                2  \n",
       "3            0.952381         0.947094        0.033797                3  \n",
       "4            1.000000         0.946960        0.047387                4  \n",
       "6            0.952381         0.941880        0.038905                5  \n",
       "8            0.952381         0.927277        0.043759                6  \n",
       "9            0.904762         0.922833        0.047883                7  \n",
       "7            0.904762         0.920293        0.045516                8  \n",
       "11           0.904762         0.876642        0.041618                9  \n",
       "12           0.904762         0.862357        0.046244               10  \n",
       "14           0.857143         0.857143        0.041000               11  \n",
       "13           0.857143         0.812991        0.044788               12  \n",
       "0            0.838095         0.739838        0.086685               13  \n",
       "10           0.666667         0.613857        0.031472               14  \n",
       "5            0.638889         0.605182        0.036480               15  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    \"preprocessor\": all_preprocessors,\n",
    "    \"classifier__n_neighbors\": [5, 51, 101],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"balanced_accuracy\",\n",
    "    cv=10,\n",
    ").fit(data, target)\n",
    "results = pd.DataFrame(grid_search.cv_results_).sort_values(\n",
    "    by=\"rank_test_score\", ascending=True\n",
    ")\n",
    "# convert the name of the preprocessor for later display\n",
    "results[\"param_preprocessor\"] = results[\"param_preprocessor\"].apply(\n",
    "    lambda x: x.__class__.__name__ if x is not None else \"None\"\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51-NN with StandardScaler is strictly better than 101-NN with StandardScaler for 10 CV iterations out of 10.\n"
     ]
    }
   ],
   "source": [
    "cv_score_columns = results.columns[results.columns.str.startswith(\"split\")]\n",
    "reference_model = results.iloc[0][cv_score_columns]\n",
    "other_model = results.iloc[8][cv_score_columns]\n",
    "print(\n",
    "    f\"51-NN with StandardScaler is strictly better than 101-NN with StandardScaler for \"\n",
    "    f\"{np.sum(reference_model.to_numpy() > other_model.to_numpy())} \"\n",
    "    \"CV iterations out of 10.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "Evaluate the generalization performance of the best models found in each fold using nested cross-validation. Set return_estimator=True and cv=10 for the outer loop. The scoring metric must be the balanced-accuracy.\n",
    "\n",
    "The mean generalization performance is :\n",
    "\n",
    " a) better than 0.97 b) between 0.92 and 0.97 c) below 0.92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    \"preprocessor\": all_preprocessors,\n",
    "    \"classifier__n_neighbors\": [5, 51, 101],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"balanced_accuracy\",\n",
    "    cv=10,\n",
    ").fit(data, target)\n",
    "results = pd.DataFrame(grid_search.cv_results_).sort_values(\n",
    "    by=\"rank_test_score\", ascending=True\n",
    ")\n",
    "# convert the name of the preprocessor for later display\n",
    "results[\"param_preprocessor\"] = results[\"param_preprocessor\"].apply(\n",
    "    lambda x: x.__class__.__name__ if x is not None else \"None\"\n",
    ")\n",
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results.sort_values(\"mean_test_score\", ascending = False).groupby(\"param_classifier__n_neighbors\").first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.971\n",
      "Generalization score with hyperparameters tuning:\n",
      "0.953 +/- 0.012\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "param_grid = {\n",
    "    \"preprocessor\": all_preprocessors,\n",
    "    \"classifier__n_neighbors\": [5, 51, 101],\n",
    "}\n",
    "\n",
    "model_grid_search = GridSearchCV(\n",
    "    model, param_grid=param_grid, n_jobs=2, cv=2\n",
    ")\n",
    "model_grid_search.fit(data, target)\n",
    "\n",
    "\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data, target, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "model_grid_search.fit(data_train, target_train)\n",
    "accuracy = model_grid_search.score(data_test, target_test)\n",
    "print(f\"Accuracy on test set: {accuracy:.3f}\")\n",
    "\n",
    "cv_results = cross_validate(\n",
    "    model_grid_search, data, target, cv=5, n_jobs=2, return_estimator=True\n",
    ")\n",
    "\n",
    "cv_results = pd.DataFrame(cv_results)\n",
    "cv_test_scores = cv_results['test_score']\n",
    "print(\n",
    "    \"Generalization score with hyperparameters tuning:\\n\"\n",
    "    f\"{cv_test_scores.mean():.3f} +/- {cv_test_scores.std():.3f}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generalization score with hyperparameters tuning:\n",
      "0.943 +/- 0.038\n"
     ]
    }
   ],
   "source": [
    "cv_results = cross_validate(\n",
    "    grid_search,\n",
    "    data,\n",
    "    target,\n",
    "    cv=10,\n",
    "    n_jobs=2,\n",
    "    scoring=\"balanced_accuracy\",\n",
    "    return_estimator=True,\n",
    ")\n",
    "cv_results = pd.DataFrame(cv_results)\n",
    "cv_test_scores = cv_results['test_score']\n",
    "\n",
    "print(\n",
    "    \"Generalization score with hyperparameters tuning:\\n\"\n",
    "    f\"{cv_test_scores.mean():.3f} +/- {cv_test_scores.std():.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7 (1 point possible)\n",
    "Explore the set of best parameters that the different grid search models found in each fold of the outer cross-validation. Remember that you can access them with the best_params_ attribute of the estimator. Select all the statements that are true.\n",
    "\n",
    " a) The tuned number of nearest neighbors is stable across all folds \n",
    " \n",
    " b) The tuned number of nearest neighbors changes often across all folds \n",
    " \n",
    " c) The optimal scaler is stable across all folds \n",
    " \n",
    " d) The optimal scaler changes often across all folds\n",
    "- unanswered\n",
    "Select all answers that apply\n",
    "Hint: it is important to pass return_estimator=True to the cross_validate function to be able to introspect trained model saved in the \"estimator\" field of the CV results. If you forgot to do for the previous question, please re-run the cross-validation with that option enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generalization score with hyperparameters tuning:\n",
      "0.943 +/- 0.038\n"
     ]
    }
   ],
   "source": [
    "cv_results1 = cross_validate(\n",
    "    grid_search,\n",
    "    data,\n",
    "    target,\n",
    "    cv=10,\n",
    "    n_jobs=2,\n",
    "    scoring=\"balanced_accuracy\",\n",
    "    return_estimator=True,\n",
    ")\n",
    "# print(cv_results)\n",
    "cv_results = pd.DataFrame(cv_results1)\n",
    "cv_test_scores = cv_results['test_score']\n",
    "\n",
    "print(\n",
    "    \"Generalization score with hyperparameters tuning:\\n\"\n",
    "    f\"{cv_test_scores.mean():.3f} +/- {cv_test_scores.std():.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_results1[\"estimator\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__n_neighbors': 5, 'preprocessor': QuantileTransformer(n_quantiles=100)}\n",
      "{'classifier__n_neighbors': 5, 'preprocessor': QuantileTransformer(n_quantiles=100)}\n",
      "{'classifier__n_neighbors': 5, 'preprocessor': StandardScaler()}\n",
      "{'classifier__n_neighbors': 5, 'preprocessor': StandardScaler()}\n",
      "{'classifier__n_neighbors': 5, 'preprocessor': MinMaxScaler()}\n",
      "{'classifier__n_neighbors': 5, 'preprocessor': QuantileTransformer(n_quantiles=100)}\n",
      "{'classifier__n_neighbors': 5, 'preprocessor': MinMaxScaler()}\n",
      "{'classifier__n_neighbors': 5, 'preprocessor': StandardScaler()}\n",
      "{'classifier__n_neighbors': 5, 'preprocessor': StandardScaler()}\n",
      "{'classifier__n_neighbors': 5, 'preprocessor': QuantileTransformer(n_quantiles=100)}\n"
     ]
    }
   ],
   "source": [
    "for estimator in cv_results1[\"estimator\"]:\n",
    "    print(estimator.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) The tuned number of nearest neighbors is stable across all folds\n",
    "\n",
    "b) The tuned number of nearest neighbors changes often across all folds\n",
    "\n",
    "c) The optimal scaler is stable across all folds\n",
    "\n",
    "d) The optimal scaler changes often across all folds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
